{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Analytics",
   "id": "3efe4bc8b29e1236"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## periodic perf",
   "id": "5b048f9e8acbe99d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T16:07:09.054383Z",
     "start_time": "2025-12-26T16:07:09.047292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "PERIODS = [\"1D\", \"1W\", \"1M\", \"YTD\", \"1Y\", \"3Y\", \"5Y\"]\n",
    "\n",
    "def _to_ts(d):\n",
    "    if d is None:\n",
    "        return None\n",
    "    return pd.Timestamp(d).normalize()\n",
    "\n",
    "def _nearest_prev_close(close: pd.Series, target_date: pd.Timestamp):\n",
    "    s = close.loc[:target_date]\n",
    "    if s.empty:\n",
    "        return None, None\n",
    "    return float(s.iloc[-1]), s.index[-1]\n",
    "\n",
    "def yahoo_perf_asof(ticker: str, asof=None, auto_adjust=True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    asof: str|date|datetime|Timestamp|None\n",
    "      - None => prend le dernier close dispo\n",
    "      - sinon => prend le dernier close <= asof\n",
    "    \"\"\"\n",
    "    t = yf.Ticker(ticker)\n",
    "\n",
    "    # On prend large pour couvrir 5Y m√™me si asof est dans le pass√©\n",
    "    # (si asof est tr√®s vieux, augmente period ou utilise start/end)\n",
    "    hist = t.history(period=\"10y\", interval=\"1d\", auto_adjust=auto_adjust)\n",
    "    if hist.empty:\n",
    "        raise ValueError(f\"No data for ticker '{ticker}'\")\n",
    "\n",
    "    close = hist[\"Close\"].dropna()\n",
    "    close.index = pd.to_datetime(close.index).tz_localize(None)\n",
    "\n",
    "    asof_ts = _to_ts(asof)\n",
    "\n",
    "    # Last price √† asOf (dernier close <= asof)\n",
    "    if asof_ts is None:\n",
    "        last_price = float(close.iloc[-1])\n",
    "        last_date = close.index[-1]\n",
    "    else:\n",
    "        last_price, last_date = _nearest_prev_close(close, asof_ts)\n",
    "        if last_price is None:\n",
    "            raise ValueError(f\"No data on or before asof={asof_ts.date()} for '{ticker}'\")\n",
    "\n",
    "    # Dates cibles relatives √† last_date (qui est le trading day retenu)\n",
    "    targets = {\n",
    "        \"1D\": last_date - pd.Timedelta(days=1),\n",
    "        \"1W\": last_date - pd.Timedelta(days=7),\n",
    "        \"1M\": last_date - pd.Timedelta(days=30),\n",
    "        \"YTD\": pd.Timestamp(year=last_date.year, month=1, day=1),\n",
    "        \"1Y\": last_date - pd.Timedelta(days=365),\n",
    "        \"3Y\": last_date - pd.Timedelta(days=365 * 3),\n",
    "        \"5Y\": last_date - pd.Timedelta(days=365 * 5),\n",
    "    }\n",
    "\n",
    "    out = {\n",
    "        \"Ticker\": ticker,\n",
    "        \"AsOfRequested\": None if asof_ts is None else asof_ts.date(),\n",
    "        \"AsOfUsed\": last_date.date(),        # trading day effectivement utilis√©\n",
    "        \"Last\": last_price,\n",
    "    }\n",
    "\n",
    "    for k, d in targets.items():\n",
    "        past_price, past_date = _nearest_prev_close(close, d)\n",
    "        if past_price is None or past_price == 0:\n",
    "            out[k] = None\n",
    "        else:\n",
    "            out[k] = (last_price / past_price - 1) * 100.0\n",
    "\n",
    "    return pd.DataFrame([out])\n",
    "\n",
    "def yahoo_perf_table_asof(tickers, asof=None, auto_adjust=True) -> pd.DataFrame:\n",
    "    dfs = [yahoo_perf_asof(t, asof=asof, auto_adjust=auto_adjust) for t in tickers]\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    pct_cols = [\"1D\", \"1W\", \"1M\", \"YTD\", \"1Y\", \"3Y\", \"5Y\"]\n",
    "    df[\"Last\"] = df[\"Last\"].round(6)\n",
    "    df[pct_cols] = df[pct_cols].round(2)\n",
    "    return df\n"
   ],
   "id": "c51d1ffd4d620c12",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T16:07:37.001310Z",
     "start_time": "2025-12-26T16:07:36.773197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = yahoo_perf_table_asof(\n",
    "    [\"AAPL\", \"SPY\", \"AIR.PA\", \"IWDA.AS\"],\n",
    "    asof=\"2025-11-01\"  # <= tu changes √ßa quand tu veux\n",
    ")\n",
    "pct_cols = [\"1D\", \"1W\", \"1M\", \"YTD\", \"1Y\", \"3Y\", \"5Y\"]\n",
    "df.style.format({**{\"Last\":\"{:.2f}\"}, **{c:\"{:+.2f}%\" for c in pct_cols}})"
   ],
   "id": "448c36c79ad5eecb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x118cfb050>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_7369e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7369e_level0_col0\" class=\"col_heading level0 col0\" >Ticker</th>\n",
       "      <th id=\"T_7369e_level0_col1\" class=\"col_heading level0 col1\" >AsOfRequested</th>\n",
       "      <th id=\"T_7369e_level0_col2\" class=\"col_heading level0 col2\" >AsOfUsed</th>\n",
       "      <th id=\"T_7369e_level0_col3\" class=\"col_heading level0 col3\" >Last</th>\n",
       "      <th id=\"T_7369e_level0_col4\" class=\"col_heading level0 col4\" >1D</th>\n",
       "      <th id=\"T_7369e_level0_col5\" class=\"col_heading level0 col5\" >1W</th>\n",
       "      <th id=\"T_7369e_level0_col6\" class=\"col_heading level0 col6\" >1M</th>\n",
       "      <th id=\"T_7369e_level0_col7\" class=\"col_heading level0 col7\" >YTD</th>\n",
       "      <th id=\"T_7369e_level0_col8\" class=\"col_heading level0 col8\" >1Y</th>\n",
       "      <th id=\"T_7369e_level0_col9\" class=\"col_heading level0 col9\" >3Y</th>\n",
       "      <th id=\"T_7369e_level0_col10\" class=\"col_heading level0 col10\" >5Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7369e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7369e_row0_col0\" class=\"data row0 col0\" >AAPL</td>\n",
       "      <td id=\"T_7369e_row0_col1\" class=\"data row0 col1\" >2025-11-01</td>\n",
       "      <td id=\"T_7369e_row0_col2\" class=\"data row0 col2\" >2025-10-31</td>\n",
       "      <td id=\"T_7369e_row0_col3\" class=\"data row0 col3\" >270.11</td>\n",
       "      <td id=\"T_7369e_row0_col4\" class=\"data row0 col4\" >-0.38%</td>\n",
       "      <td id=\"T_7369e_row0_col5\" class=\"data row0 col5\" >+2.87%</td>\n",
       "      <td id=\"T_7369e_row0_col6\" class=\"data row0 col6\" >+5.84%</td>\n",
       "      <td id=\"T_7369e_row0_col7\" class=\"data row0 col7\" >+8.35%</td>\n",
       "      <td id=\"T_7369e_row0_col8\" class=\"data row0 col8\" >+20.24%</td>\n",
       "      <td id=\"T_7369e_row0_col9\" class=\"data row0 col9\" >+82.30%</td>\n",
       "      <td id=\"T_7369e_row0_col10\" class=\"data row0 col10\" >+155.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7369e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7369e_row1_col0\" class=\"data row1 col0\" >SPY</td>\n",
       "      <td id=\"T_7369e_row1_col1\" class=\"data row1 col1\" >2025-11-01</td>\n",
       "      <td id=\"T_7369e_row1_col2\" class=\"data row1 col2\" >2025-10-31</td>\n",
       "      <td id=\"T_7369e_row1_col3\" class=\"data row1 col3\" >680.05</td>\n",
       "      <td id=\"T_7369e_row1_col4\" class=\"data row1 col4\" >+0.33%</td>\n",
       "      <td id=\"T_7369e_row1_col5\" class=\"data row1 col5\" >+0.71%</td>\n",
       "      <td id=\"T_7369e_row1_col6\" class=\"data row1 col6\" >+2.04%</td>\n",
       "      <td id=\"T_7369e_row1_col7\" class=\"data row1 col7\" >+17.40%</td>\n",
       "      <td id=\"T_7369e_row1_col8\" class=\"data row1 col8\" >+21.40%</td>\n",
       "      <td id=\"T_7369e_row1_col9\" class=\"data row1 col9\" >+84.83%</td>\n",
       "      <td id=\"T_7369e_row1_col10\" class=\"data row1 col10\" >+124.05%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7369e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7369e_row2_col0\" class=\"data row2 col0\" >AIR.PA</td>\n",
       "      <td id=\"T_7369e_row2_col1\" class=\"data row2 col1\" >2025-11-01</td>\n",
       "      <td id=\"T_7369e_row2_col2\" class=\"data row2 col2\" >2025-10-31</td>\n",
       "      <td id=\"T_7369e_row2_col3\" class=\"data row2 col3\" >213.40</td>\n",
       "      <td id=\"T_7369e_row2_col4\" class=\"data row2 col4\" >+0.33%</td>\n",
       "      <td id=\"T_7369e_row2_col5\" class=\"data row2 col5\" >+2.37%</td>\n",
       "      <td id=\"T_7369e_row2_col6\" class=\"data row2 col6\" >+7.19%</td>\n",
       "      <td id=\"T_7369e_row2_col7\" class=\"data row2 col7\" >+40.97%</td>\n",
       "      <td id=\"T_7369e_row2_col8\" class=\"data row2 col8\" >+55.68%</td>\n",
       "      <td id=\"T_7369e_row2_col9\" class=\"data row2 col9\" >+100.10%</td>\n",
       "      <td id=\"T_7369e_row2_col10\" class=\"data row2 col10\" >+264.89%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7369e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7369e_row3_col0\" class=\"data row3 col0\" >IWDA.AS</td>\n",
       "      <td id=\"T_7369e_row3_col1\" class=\"data row3 col1\" >2025-11-01</td>\n",
       "      <td id=\"T_7369e_row3_col2\" class=\"data row3 col2\" >2025-10-31</td>\n",
       "      <td id=\"T_7369e_row3_col3\" class=\"data row3 col3\" >111.79</td>\n",
       "      <td id=\"T_7369e_row3_col4\" class=\"data row3 col4\" >-0.12%</td>\n",
       "      <td id=\"T_7369e_row3_col5\" class=\"data row3 col5\" >+1.09%</td>\n",
       "      <td id=\"T_7369e_row3_col6\" class=\"data row3 col6\" >+3.49%</td>\n",
       "      <td id=\"T_7369e_row3_col7\" class=\"data row3 col7\" >+7.32%</td>\n",
       "      <td id=\"T_7369e_row3_col8\" class=\"data row3 col8\" >+14.59%</td>\n",
       "      <td id=\"T_7369e_row3_col9\" class=\"data row3 col9\" >+54.26%</td>\n",
       "      <td id=\"T_7369e_row3_col10\" class=\"data row3 col10\" >+108.89%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Returns",
   "id": "c822ef1d0a7ed1c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T18:08:40.842862Z",
     "start_time": "2025-12-26T18:08:40.839102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "def arithmetic_return_from_series(\n",
    "    prices: pd.Series,\n",
    "    start_date: str,\n",
    "    end_date: str\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Calcule un rendement arithm√©tique √† partir d'une s√©rie de prix (index√©e par date).\n",
    "\n",
    "    prices : pd.Series\n",
    "        S√©rie de prix (id√©alement cl√¥ture ajust√©e), index = datetime\n",
    "    start_date / end_date : YYYY-MM-DD\n",
    "    \"\"\"\n",
    "\n",
    "    if prices.empty:\n",
    "        raise ValueError(\"Price series is empty.\")\n",
    "\n",
    "    prices = prices.dropna().copy()\n",
    "    prices.index = pd.to_datetime(prices.index).tz_localize(None)\n",
    "\n",
    "    start_ts = pd.Timestamp(start_date)\n",
    "    end_ts = pd.Timestamp(end_date)\n",
    "\n",
    "    if start_ts > end_ts:\n",
    "        raise ValueError(\"start_date must be <= end_date\")\n",
    "\n",
    "    start_slice = prices.loc[:start_ts]\n",
    "    end_slice = prices.loc[:end_ts]\n",
    "\n",
    "    if start_slice.empty:\n",
    "        raise ValueError(f\"No price data on or before {start_ts.date()}\")\n",
    "    if end_slice.empty:\n",
    "        raise ValueError(f\"No price data on or before {end_ts.date()}\")\n",
    "\n",
    "    start_price = float(start_slice.iloc[-1])\n",
    "    end_price = float(end_slice.iloc[-1])\n",
    "\n",
    "    return {\n",
    "        \"StartDateRequested\": start_ts.date(),\n",
    "        \"EndDateRequested\": end_ts.date(),\n",
    "        \"StartDateUsed\": start_slice.index[-1].date(),\n",
    "        \"EndDateUsed\": end_slice.index[-1].date(),\n",
    "        \"StartPrice\": start_price,\n",
    "        \"EndPrice\": end_price,\n",
    "        \"ArithmeticReturn\": end_price / start_price - 1,\n",
    "    }\n"
   ],
   "id": "1fcd3b754ba57dca",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T18:08:41.251086Z",
     "start_time": "2025-12-26T18:08:41.246856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "def _price_on_or_near(\n",
    "    prices: pd.Series,\n",
    "    target: pd.Timestamp,\n",
    "    direction: str = \"backward\"  # backward | forward\n",
    "):\n",
    "    \"\"\"\n",
    "    Retourne (price: float, date_used: Timestamp)\n",
    "    Compatible pandas >= 2.x (no FutureWarning)\n",
    "    \"\"\"\n",
    "\n",
    "    if direction == \"backward\":\n",
    "        s = prices.loc[:target]\n",
    "        if not s.empty:\n",
    "            price = s.iloc[-1].item()   # üëà SCALAIRE GARANTI\n",
    "            return float(price), s.index[-1]\n",
    "\n",
    "    elif direction == \"forward\":\n",
    "        s = prices.loc[target:]\n",
    "        if not s.empty:\n",
    "            price = s.iloc[0].item()    # üëà SCALAIRE GARANTI\n",
    "            return float(price), s.index[0]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"direction must be 'backward' or 'forward'\")\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def arithmetic_return_from_series(\n",
    "    prices: pd.Series,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    fallback_start: str = \"forward\",   # üëà cl√© ici\n",
    "    fallback_end: str = \"backward\"\n",
    ") -> dict:\n",
    "    prices = prices.dropna().copy()\n",
    "    prices.index = pd.to_datetime(prices.index).tz_localize(None)\n",
    "\n",
    "    start_ts = pd.Timestamp(start_date)\n",
    "    end_ts = pd.Timestamp(end_date)\n",
    "\n",
    "    if start_ts > end_ts:\n",
    "        raise ValueError(\"start_date must be <= end_date\")\n",
    "\n",
    "    # --- start price ---\n",
    "    start_price, start_used = _price_on_or_near(\n",
    "        prices, start_ts, direction=\"backward\"\n",
    "    )\n",
    "    if start_price is None and fallback_start == \"forward\":\n",
    "        start_price, start_used = _price_on_or_near(\n",
    "            prices, start_ts, direction=\"forward\"\n",
    "        )\n",
    "\n",
    "    # --- end price ---\n",
    "    end_price, end_used = _price_on_or_near(\n",
    "        prices, end_ts, direction=\"backward\"\n",
    "    )\n",
    "    if end_price is None and fallback_end == \"forward\":\n",
    "        end_price, end_used = _price_on_or_near(\n",
    "            prices, end_ts, direction=\"forward\"\n",
    "        )\n",
    "\n",
    "    if start_price is None:\n",
    "        raise ValueError(f\"No price data around start_date={start_date}\")\n",
    "    if end_price is None:\n",
    "        raise ValueError(f\"No price data around end_date={end_date}\")\n",
    "\n",
    "    return {\n",
    "        \"StartDateRequested\": start_ts.date(),\n",
    "        \"EndDateRequested\": end_ts.date(),\n",
    "        \"StartDateUsed\": start_used.date(),\n",
    "        \"EndDateUsed\": end_used.date(),\n",
    "        \"StartPrice\": start_price,\n",
    "        \"EndPrice\": end_price,\n",
    "        \"ArithmeticReturn\": end_price / start_price - 1,\n",
    "    }\n"
   ],
   "id": "8f2458354791bf00",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T18:08:41.980294Z",
     "start_time": "2025-12-26T18:08:41.976198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yfinance as yf\n",
    "\n",
    "def yahoo_adjusted_return(\n",
    "    ticker: str,\n",
    "    start_date: str,\n",
    "    end_date: str\n",
    ") -> dict:\n",
    "    df = yf.download(\n",
    "        ticker,\n",
    "        start=start_date,\n",
    "        end=pd.to_datetime(end_date) + pd.Timedelta(days=1),\n",
    "        auto_adjust=True,\n",
    "        progress=False\n",
    "    )\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No data returned for ticker {ticker}\")\n",
    "\n",
    "    prices = df[\"Close\"]\n",
    "\n",
    "    res = arithmetic_return_from_series(\n",
    "        prices=prices,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        fallback_start=\"forward\",   # üëà crucial\n",
    "        fallback_end=\"backward\"\n",
    "    )\n",
    "\n",
    "    res[\"Ticker\"] = ticker\n",
    "    res[\"PriceType\"] = \"Adjusted Close\"\n",
    "\n",
    "    return res\n"
   ],
   "id": "965cc7c518f5a42f",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T18:10:52.268813Z",
     "start_time": "2025-12-26T18:10:52.117128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "yahoo_adjusted_return(\n",
    "    ticker=\"PUST.PA\",\n",
    "    start_date=\"2025-01-01\",\n",
    "    end_date=\"2025-12-25\"\n",
    ")\n"
   ],
   "id": "f5491530e55853ec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'StartDateRequested': datetime.date(2025, 1, 1),\n",
       " 'EndDateRequested': datetime.date(2025, 12, 25),\n",
       " 'StartDateUsed': datetime.date(2025, 1, 2),\n",
       " 'EndDateUsed': datetime.date(2025, 12, 24),\n",
       " 'StartPrice': 82.56999969482422,\n",
       " 'EndPrice': 87.1500015258789,\n",
       " 'ArithmeticReturn': 0.05546811006397245,\n",
       " 'Ticker': 'PUST.PA',\n",
       " 'PriceType': 'Adjusted Close'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Cumulative returns",
   "id": "e7043c47c9945188"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T18:15:04.108233Z",
     "start_time": "2025-12-26T18:15:04.105483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "def cumulative_return_from_prices(\n",
    "    prices: pd.Series,\n",
    "    start_date: str | None = None,\n",
    "    end_date: str | None = None\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calcule le cumulative return √† partir d'une s√©rie de prix ajust√©s.\n",
    "\n",
    "    prices : pd.Series (index datetime, valeurs = adjusted close)\n",
    "    start_date / end_date : optionnels (YYYY-MM-DD)\n",
    "\n",
    "    Retourne une Series de cumulative returns (0 au point de d√©part).\n",
    "    \"\"\"\n",
    "\n",
    "    prices = prices.dropna().copy()\n",
    "    prices.index = pd.to_datetime(prices.index).tz_localize(None)\n",
    "\n",
    "    if start_date:\n",
    "        prices = prices.loc[pd.Timestamp(start_date):]\n",
    "    if end_date:\n",
    "        prices = prices.loc[:pd.Timestamp(end_date)]\n",
    "\n",
    "    if len(prices) < 2:\n",
    "        raise ValueError(\"Not enough data to compute cumulative return\")\n",
    "\n",
    "    base_price = prices.iloc[0].item()\n",
    "\n",
    "    cumret = prices / base_price - 1\n",
    "    cumret.name = \"CumulativeReturn\"\n",
    "\n",
    "    return cumret\n"
   ],
   "id": "652b01ddf37c88e",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T18:15:14.310628Z",
     "start_time": "2025-12-26T18:15:14.308387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yfinance as yf\n",
    "\n",
    "def yahoo_cumulative_return(\n",
    "    ticker: str,\n",
    "    start_date: str,\n",
    "    end_date: str\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Cumulative return bas√© sur la cl√¥ture ajust√©e Yahoo Finance.\n",
    "    \"\"\"\n",
    "\n",
    "    df = yf.download(\n",
    "        ticker,\n",
    "        start=start_date,\n",
    "        end=pd.to_datetime(end_date) + pd.Timedelta(days=1),\n",
    "        auto_adjust=True,   # <<< cl√©\n",
    "        progress=False\n",
    "    )\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No data returned for {ticker}\")\n",
    "\n",
    "    prices = df[\"Close\"]\n",
    "\n",
    "    return cumulative_return_from_prices(\n",
    "        prices=prices,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date\n",
    "    )\n"
   ],
   "id": "7abc260a71bd9f0b",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T18:19:48.436009Z",
     "start_time": "2025-12-26T18:19:47.223890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cumret = yahoo_cumulative_return(\n",
    "    ticker=\"PUST.PA\",\n",
    "    start_date=\"2023-11-01\",\n",
    "    end_date=\"2025-12-26\"\n",
    ")\n",
    "\n",
    "cumret.tail()\n"
   ],
   "id": "62af90e3e6a1426a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ticker       PUST.PA\n",
       "Date                \n",
       "2025-12-18  0.560821\n",
       "2025-12-19  0.573529\n",
       "2025-12-22  0.576416\n",
       "2025-12-23  0.578431\n",
       "2025-12-24  0.582244"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>PUST.PA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-12-18</th>\n",
       "      <td>0.560821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-19</th>\n",
       "      <td>0.573529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-22</th>\n",
       "      <td>0.576416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-23</th>\n",
       "      <td>0.578431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-24</th>\n",
       "      <td>0.582244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Rolling Returns",
   "id": "d2d42d96f009847a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T18:21:48.702115Z",
     "start_time": "2025-12-26T18:21:48.699953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "ROLLING_WINDOWS = {\n",
    "    \"1M\": 21,\n",
    "    \"3M\": 63,\n",
    "    \"12M\": 252,\n",
    "}\n",
    "\n",
    "def rolling_returns_from_prices(\n",
    "    prices: pd.Series,\n",
    "    windows: dict[str, int] = ROLLING_WINDOWS\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    prices : pd.Series (Adjusted Close, index datetime)\n",
    "    retourne un DataFrame avec une colonne par fen√™tre\n",
    "    \"\"\"\n",
    "\n",
    "    prices = prices.dropna().copy()\n",
    "    prices.index = pd.to_datetime(prices.index).tz_localize(None)\n",
    "\n",
    "    out = pd.DataFrame(index=prices.index)\n",
    "\n",
    "    for label, n in windows.items():\n",
    "        out[f\"RollingReturn_{label}\"] = prices / prices.shift(n) - 1\n",
    "\n",
    "    return out\n"
   ],
   "id": "a10b64b49abf5526",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T18:21:54.140051Z",
     "start_time": "2025-12-26T18:21:54.137764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yfinance as yf\n",
    "\n",
    "def yahoo_rolling_returns(\n",
    "    ticker: str,\n",
    "    start_date: str,\n",
    "    end_date: str\n",
    ") -> pd.DataFrame:\n",
    "    df = yf.download(\n",
    "        ticker,\n",
    "        start=start_date,\n",
    "        end=pd.to_datetime(end_date) + pd.Timedelta(days=1),\n",
    "        auto_adjust=True,\n",
    "        progress=False\n",
    "    )\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No data returned for {ticker}\")\n",
    "\n",
    "    prices = df[\"Close\"]\n",
    "\n",
    "    rr = rolling_returns_from_prices(prices)\n",
    "    rr[\"Ticker\"] = ticker\n",
    "\n",
    "    return rr\n"
   ],
   "id": "b70f14914033e4a1",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T18:22:03.202792Z",
     "start_time": "2025-12-26T18:22:03.200461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rolling_return_distribution(\n",
    "    rolling_returns: pd.DataFrame,\n",
    "    quantiles=(0.05, 0.25, 0.5, 0.75, 0.95)\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    rolling_returns : DataFrame issu de rolling_returns_from_prices\n",
    "    \"\"\"\n",
    "\n",
    "    stats = {}\n",
    "\n",
    "    for col in rolling_returns.columns:\n",
    "        if not col.startswith(\"RollingReturn_\"):\n",
    "            continue\n",
    "\n",
    "        s = rolling_returns[col].dropna()\n",
    "\n",
    "        q = s.quantile(quantiles)\n",
    "\n",
    "        stats[col] = {\n",
    "            \"Median\": q.loc[0.5],\n",
    "            \"Q25\": q.loc[0.25],\n",
    "            \"Q75\": q.loc[0.75],\n",
    "            \"IQR\": q.loc[0.75] - q.loc[0.25],\n",
    "            \"P05\": q.loc[0.05],\n",
    "            \"P95\": q.loc[0.95],\n",
    "            \"Min\": s.min(),\n",
    "            \"Max\": s.max(),\n",
    "            \"Obs\": len(s),\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame(stats).T\n"
   ],
   "id": "dbf3afb13a28b0f1",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T18:23:32.028282Z",
     "start_time": "2025-12-26T18:23:31.995651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rr = yahoo_rolling_returns(\n",
    "    ticker=\"AAPL\",\n",
    "    start_date=\"2018-01-01\",\n",
    "    end_date=\"2024-01-01\"\n",
    ")\n",
    "\n",
    "dist = rolling_return_distribution(rr)\n",
    "\n",
    "rr, dist\n"
   ],
   "id": "2ac7a100f2e68a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            RollingReturn_1M  RollingReturn_3M  RollingReturn_12M Ticker\n",
       " Date                                                                    \n",
       " 2018-01-02               NaN               NaN                NaN   AAPL\n",
       " 2018-01-03               NaN               NaN                NaN   AAPL\n",
       " 2018-01-04               NaN               NaN                NaN   AAPL\n",
       " 2018-01-05               NaN               NaN                NaN   AAPL\n",
       " 2018-01-08               NaN               NaN                NaN   AAPL\n",
       " ...                      ...               ...                ...    ...\n",
       " 2023-12-22          0.011970          0.100949           0.437299   AAPL\n",
       " 2023-12-26          0.016213          0.124124           0.468116   AAPL\n",
       " 2023-12-27          0.017704          0.134803           0.472999   AAPL\n",
       " 2023-12-28          0.016702          0.135597           0.497054   AAPL\n",
       " 2023-12-29          0.016687          0.126007           0.536069   AAPL\n",
       " \n",
       " [1509 rows x 4 columns],\n",
       "                      Median       Q25       Q75       IQR       P05       P95  \\\n",
       " RollingReturn_1M   0.034730 -0.031183  0.085963  0.117145 -0.124877  0.154945   \n",
       " RollingReturn_3M   0.078065 -0.023006  0.176134  0.199141 -0.176675  0.340747   \n",
       " RollingReturn_12M  0.276007  0.061797  0.610867  0.549070 -0.101490  1.050859   \n",
       " \n",
       "                         Min       Max     Obs  \n",
       " RollingReturn_1M  -0.284296  0.361382  1488.0  \n",
       " RollingReturn_3M  -0.377677  0.653813  1446.0  \n",
       " RollingReturn_12M -0.301723  1.635125  1257.0  )"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Drawdown Analysis",
   "id": "f6ce866093863145"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T18:30:17.637775Z",
     "start_time": "2025-12-26T18:30:17.629871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Drawdown analysis (robuste)\n",
    "# =========================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def _as_price_series(prices) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Accepte pd.Series ou pd.DataFrame (yfinance, MultiIndex inclus)\n",
    "    et retourne UNE Series de prix.\n",
    "    \"\"\"\n",
    "    if isinstance(prices, pd.Series):\n",
    "        s = prices\n",
    "    elif isinstance(prices, pd.DataFrame):\n",
    "        if prices.shape[1] == 1:\n",
    "            s = prices.iloc[:, 0]\n",
    "        else:\n",
    "            # fallback: premi√®re colonne\n",
    "            s = prices.iloc[:, 0]\n",
    "    else:\n",
    "        raise TypeError(\"prices must be a pandas Series or DataFrame\")\n",
    "\n",
    "    s = s.dropna().copy()\n",
    "    s.index = pd.to_datetime(s.index).tz_localize(None)\n",
    "    return s\n",
    "\n",
    "\n",
    "def drawdown_series(prices) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retourne un DataFrame avec :\n",
    "      - Price\n",
    "      - RunningMax\n",
    "      - Drawdown\n",
    "    \"\"\"\n",
    "    p = _as_price_series(prices)\n",
    "\n",
    "    running_max = p.cummax()\n",
    "    drawdown = p / running_max - 1.0\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"Price\": p,\n",
    "        \"RunningMax\": running_max,\n",
    "        \"Drawdown\": drawdown\n",
    "    })\n",
    "\n",
    "\n",
    "def drawdown_metrics(prices) -> dict:\n",
    "    \"\"\"\n",
    "    Calcule :\n",
    "      - Max drawdown\n",
    "      - Current drawdown\n",
    "      - Nombre d'√©pisodes\n",
    "      - Dur√©e moyenne / max des drawdowns (jours de trading)\n",
    "    \"\"\"\n",
    "    dd_df = drawdown_series(prices)\n",
    "    dd = dd_df[\"Drawdown\"]\n",
    "\n",
    "    max_dd = float(dd.min())\n",
    "    current_dd = float(dd.iloc[-1].item())\n",
    "\n",
    "    # Identification des √©pisodes de drawdown\n",
    "    in_dd = dd < 0\n",
    "    episode_id = (in_dd != in_dd.shift(1, fill_value=False)).cumsum()\n",
    "\n",
    "    durations = []\n",
    "    troughs = []\n",
    "\n",
    "    for _, block in dd_df[in_dd].groupby(episode_id[in_dd]):\n",
    "        durations.append(len(block))                    # jours de trading\n",
    "        troughs.append(float(block[\"Drawdown\"].min()))  # trough de l'√©pisode\n",
    "\n",
    "    return {\n",
    "        \"MaxDrawdown\": max_dd,\n",
    "        \"CurrentDrawdown\": current_dd,\n",
    "        \"NumDrawdownEpisodes\": int(len(durations)),\n",
    "        \"AvgDrawdownLength_trading_days\": float(pd.Series(durations).mean()) if durations else 0.0,\n",
    "        \"MaxDrawdownLength_trading_days\": int(max(durations)) if durations else 0,\n",
    "        \"WorstEpisodeTrough\": float(min(troughs)) if troughs else 0.0,\n",
    "    }\n",
    "\n",
    "\n",
    "def max_drawdown_path(prices) -> dict:\n",
    "    \"\"\"\n",
    "    Dates du pire drawdown :\n",
    "      - Peak\n",
    "      - Trough\n",
    "      - Recovery (si atteint)\n",
    "    \"\"\"\n",
    "    dd_df = drawdown_series(prices)\n",
    "\n",
    "    p = dd_df[\"Price\"]\n",
    "    dd = dd_df[\"Drawdown\"]\n",
    "\n",
    "    trough_date = dd.idxmin()\n",
    "    trough_dd = float(dd.loc[trough_date])\n",
    "\n",
    "    peak_date = p.loc[:trough_date].idxmax()\n",
    "    peak_price = float(p.loc[peak_date].item())\n",
    "\n",
    "    # Recovery = retour au niveau du peak\n",
    "    after = p.loc[trough_date:]\n",
    "    rec = after[after >= peak_price]\n",
    "    recovery_date = rec.index[0] if not rec.empty else None\n",
    "\n",
    "    return {\n",
    "        \"PeakDate\": peak_date.date(),\n",
    "        \"TroughDate\": trough_date.date(),\n",
    "        \"RecoveryDate\": None if recovery_date is None else recovery_date.date(),\n",
    "        \"MaxDrawdown\": trough_dd,\n",
    "    }\n"
   ],
   "id": "7b0aad43e0997550",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T21:48:48.416486Z",
     "start_time": "2025-12-26T21:48:48.185537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yfinance as yf\n",
    "\n",
    "df = yf.download(\"AAPL\", start=\"2025-01-01\", end=\"2025-12-25\", auto_adjust=True, progress=False)\n",
    "prices = df[\"Close\"]\n",
    "\n",
    "dd_df = drawdown_series(prices)\n",
    "metrics = drawdown_metrics(prices)\n",
    "path = max_drawdown_path(prices)\n",
    "\n",
    "metrics, path, dd_df\n"
   ],
   "id": "e09af3d06558ad78",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'MaxDrawdown': -0.30222577832657394,\n",
       "  'CurrentDrawdown': -0.043257992163255765,\n",
       "  'NumDrawdownEpisodes': 12,\n",
       "  'AvgDrawdownLength_trading_days': 18.5,\n",
       "  'MaxDrawdownLength_trading_days': 144,\n",
       "  'WorstEpisodeTrough': -0.30222577832657394},\n",
       " {'PeakDate': datetime.date(2025, 2, 24),\n",
       "  'TroughDate': datetime.date(2025, 4, 8),\n",
       "  'RecoveryDate': datetime.date(2025, 9, 22),\n",
       "  'MaxDrawdown': -0.30222577832657394},\n",
       "                  Price  RunningMax  Drawdown\n",
       " Date                                        \n",
       " 2025-01-02  242.752090  242.752090  0.000000\n",
       " 2025-01-03  242.264297  242.752090 -0.002009\n",
       " 2025-01-06  243.896927  243.896927  0.000000\n",
       " 2025-01-07  241.119476  243.896927 -0.011388\n",
       " 2025-01-08  241.607269  243.896927 -0.009388\n",
       " ...                ...         ...       ...\n",
       " 2025-12-18  272.190002  286.190002 -0.048919\n",
       " 2025-12-19  273.670013  286.190002 -0.043747\n",
       " 2025-12-22  270.970001  286.190002 -0.053181\n",
       " 2025-12-23  272.359985  286.190002 -0.048325\n",
       " 2025-12-24  273.809998  286.190002 -0.043258\n",
       " \n",
       " [246 rows x 3 columns])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 142
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Realized Volatility",
   "id": "6d137e886221f5f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:41:55.027993Z",
     "start_time": "2025-12-26T20:41:55.025563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def realized_volatility(\n",
    "    returns: pd.Series,\n",
    "    freq: str = \"daily\",     # daily | weekly\n",
    "    annualize: bool = True\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Calcule la volatilit√© r√©alis√©e (daily / weekly) et annualis√©e.\n",
    "\n",
    "    returns : pd.Series de returns simples\n",
    "    \"\"\"\n",
    "\n",
    "    r = returns.dropna().copy()\n",
    "    if len(r) < 10:\n",
    "        raise ValueError(\"Not enough observations to compute volatility\")\n",
    "\n",
    "    vol = r.std(ddof=1).item()\n",
    "\n",
    "    if freq == \"daily\":\n",
    "        ann_factor = np.sqrt(252)\n",
    "    elif freq == \"weekly\":\n",
    "        ann_factor = np.sqrt(52)\n",
    "    else:\n",
    "        raise ValueError(\"freq must be 'daily' or 'weekly'\")\n",
    "\n",
    "    vol_ann = vol * ann_factor if annualize else None\n",
    "\n",
    "    return {\n",
    "        \"Observations\": int(len(r)),\n",
    "        \"Volatility\": float(vol),\n",
    "        \"AnnualizedVolatility\": float(vol_ann) if annualize else None,\n",
    "        \"Frequency\": freq,\n",
    "    }\n"
   ],
   "id": "d4a249bb6704ee29",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:41:55.432267Z",
     "start_time": "2025-12-26T20:41:55.430027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yfinance as yf\n",
    "\n",
    "def yahoo_realized_volatility(\n",
    "    ticker: str,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    freq: str = \"daily\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Realized volatility depuis Yahoo Finance (Adjusted Close).\n",
    "    \"\"\"\n",
    "\n",
    "    df = yf.download(\n",
    "        ticker,\n",
    "        start=start_date,\n",
    "        end=pd.to_datetime(end_date) + pd.Timedelta(days=1),\n",
    "        auto_adjust=True,\n",
    "        progress=False\n",
    "    )\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No data returned for {ticker}\")\n",
    "\n",
    "    prices = df[\"Close\"].dropna()\n",
    "\n",
    "    if freq == \"daily\":\n",
    "        returns = prices.pct_change()\n",
    "\n",
    "    elif freq == \"weekly\":\n",
    "        weekly_prices = prices.resample(\"W-FRI\").last()\n",
    "        returns = weekly_prices.pct_change()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"freq must be 'daily' or 'weekly'\")\n",
    "\n",
    "    out = realized_volatility(\n",
    "        returns=returns,\n",
    "        freq=freq,\n",
    "        annualize=True\n",
    "    )\n",
    "\n",
    "    out[\"Ticker\"] = ticker\n",
    "    out[\"PriceType\"] = \"Adjusted Close\"\n",
    "\n",
    "    return out\n"
   ],
   "id": "abd4c2ac2805d96e",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:43:11.970313Z",
     "start_time": "2025-12-26T20:43:11.953583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "yahoo_realized_volatility(\n",
    "    ticker=\"CAC.PA\",\n",
    "    start_date=\"2025-01-01\",\n",
    "    end_date=\"2025-12-25\",\n",
    "    freq=\"daily\"\n",
    ")\n"
   ],
   "id": "c5f8dde5bd12c603",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Observations': 251,\n",
       " 'Volatility': 0.009858624844537691,\n",
       " 'AnnualizedVolatility': 0.15650081764637727,\n",
       " 'Frequency': 'daily',\n",
       " 'Ticker': 'CAC.PA',\n",
       " 'PriceType': 'Adjusted Close'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Expected shortfall (more complete integrate already VaR)",
   "id": "e401a9b297fca54f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T22:11:42.219908Z",
     "start_time": "2025-12-26T22:11:42.209819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from scipy.stats import norm\n",
    "\n",
    "def _as_price_series(x) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Force une sortie yfinance (Series/DataFrame, colonnes simples ou MultiIndex)\n",
    "    en Series 1D de prix.\n",
    "    \"\"\"\n",
    "    if isinstance(x, pd.Series):\n",
    "        s = x\n",
    "    elif isinstance(x, pd.DataFrame):\n",
    "        # 1 colonne -> OK, sinon on prend la 1√®re\n",
    "        s = x.iloc[:, 0]\n",
    "    else:\n",
    "        raise TypeError(\"Expected pandas Series or DataFrame\")\n",
    "\n",
    "    s = s.dropna().copy()\n",
    "    s.index = pd.to_datetime(s.index).tz_localize(None)\n",
    "    return s\n",
    "\n",
    "\n",
    "def _as_return_series(returns) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Assure que returns est une Series 1D.\n",
    "    \"\"\"\n",
    "    if isinstance(returns, pd.Series):\n",
    "        s = returns\n",
    "    elif isinstance(returns, pd.DataFrame):\n",
    "        s = returns.iloc[:, 0]\n",
    "    else:\n",
    "        raise TypeError(\"Expected pandas Series or DataFrame\")\n",
    "    return s.dropna().copy()\n",
    "\n",
    "\n",
    "# ---------- VaR ----------\n",
    "\n",
    "def var_historical(returns: pd.Series, alpha: float) -> float:\n",
    "    r = _as_return_series(returns).to_numpy()\n",
    "    q = np.quantile(r, 1 - alpha)\n",
    "    return float(-q)  # perte positive\n",
    "\n",
    "\n",
    "def var_gaussian(returns: pd.Series, alpha: float) -> float:\n",
    "    r = _as_return_series(returns)\n",
    "    mu = r.mean().item()\n",
    "    sigma = r.std(ddof=1).item()\n",
    "    z = norm.ppf(1 - alpha)\n",
    "    return float(-(mu + z * sigma))\n",
    "\n",
    "\n",
    "def var_cornish_fisher(returns: pd.Series, alpha: float) -> float:\n",
    "    r = _as_return_series(returns)\n",
    "    mu = r.mean().item()\n",
    "    sigma = r.std(ddof=1).item()\n",
    "    S = r.skew().item()\n",
    "    K = r.kurt().item()  # excess kurtosis\n",
    "\n",
    "    z = norm.ppf(1 - alpha)\n",
    "    z_cf = (\n",
    "        z\n",
    "        + (1/6)  * (z**2 - 1) * S\n",
    "        + (1/24) * (z**3 - 3*z) * K\n",
    "        - (1/36) * (2*z**3 - 5*z) * (S**2)\n",
    "    )\n",
    "    return float(-(mu + z_cf * sigma))\n",
    "\n",
    "\n",
    "# ---------- ES / CVaR ----------\n",
    "\n",
    "def es_historical(returns: pd.Series, alpha: float) -> float:\n",
    "    r = _as_return_series(returns).to_numpy()\n",
    "    q = np.quantile(r, 1 - alpha)      # seuil en return (queue gauche)\n",
    "    tail = r[r <= q]\n",
    "    return float(-np.mean(tail)) if tail.size else 0.0  # perte positive\n",
    "\n",
    "\n",
    "def es_gaussian(returns: pd.Series, alpha: float) -> float:\n",
    "    r = _as_return_series(returns)\n",
    "    mu = r.mean().item()\n",
    "    sigma = r.std(ddof=1).item()\n",
    "\n",
    "    z_left = norm.ppf(1 - alpha)       # n√©gatif\n",
    "    phi = norm.pdf(z_left)\n",
    "\n",
    "    # ES (return) c√¥t√© gauche sous normalit√©\n",
    "    es_return = mu - sigma * (phi / (1 - alpha))\n",
    "    return float(-es_return)           # perte positive\n",
    "\n",
    "\n",
    "def es_cf_empirical_tail(returns: pd.Series, alpha: float) -> float:\n",
    "    \"\"\"\n",
    "    Pratique : seuil VaR Cornish-Fisher, puis moyenne empirique des returns <= seuil.\n",
    "    \"\"\"\n",
    "    r = _as_return_series(returns).to_numpy()\n",
    "    var_cf_loss = var_cornish_fisher(pd.Series(r), alpha)\n",
    "    threshold_return = -var_cf_loss\n",
    "\n",
    "    tail = r[r <= threshold_return]\n",
    "    return float(-np.mean(tail)) if tail.size else 0.0\n",
    "\n",
    "\n",
    "def es_summary(returns: pd.Series, confidence_levels=(0.95, 0.99)) -> pd.DataFrame:\n",
    "    r = _as_return_series(returns)\n",
    "\n",
    "    rows = []\n",
    "    for alpha in confidence_levels:\n",
    "        rows.append({\n",
    "            \"ConfidenceLevel\": alpha,\n",
    "            \"VaR_Historical\": var_historical(r, alpha),\n",
    "            \"ES_Historical\": es_historical(r, alpha),\n",
    "            \"VaR_Gaussian\": var_gaussian(r, alpha),\n",
    "            \"ES_Gaussian\": es_gaussian(r, alpha),\n",
    "            \"VaR_CornishFisher\": var_cornish_fisher(r, alpha),\n",
    "            \"ES_CF_EmpiricalTail\": es_cf_empirical_tail(r, alpha),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def yahoo_es(ticker: str, start_date: str, end_date: str, confidence_levels=(0.95, 0.99)) -> pd.DataFrame:\n",
    "    df = yf.download(\n",
    "        ticker,\n",
    "        start=start_date,\n",
    "        end=pd.to_datetime(end_date) + pd.Timedelta(days=1),\n",
    "        auto_adjust=True,\n",
    "        progress=False\n",
    "    )\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No data for {ticker}\")\n",
    "\n",
    "    prices = _as_price_series(df[\"Close\"])\n",
    "    returns = prices.pct_change()\n",
    "\n",
    "    out = es_summary(returns, confidence_levels)\n",
    "    out[\"Ticker\"] = ticker\n",
    "    out[\"ReturnType\"] = \"SimpleReturns\"\n",
    "    out[\"Horizon\"] = \"1D\"\n",
    "    return out\n"
   ],
   "id": "6afef5f6294093d2",
   "outputs": [],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T22:11:43.364433Z",
     "start_time": "2025-12-26T22:11:43.345137Z"
    }
   },
   "cell_type": "code",
   "source": "yahoo_es(\"AAPL\", \"2025-01-01\", \"2025-12-25\")\n",
   "id": "8da912b0e6730805",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   ConfidenceLevel  VaR_Historical  ES_Historical  VaR_Gaussian  ES_Gaussian  \\\n",
       "0             0.95        0.032191       0.045673      0.033205     0.041819   \n",
       "1             0.99        0.049229       0.071721      0.047253     0.054238   \n",
       "\n",
       "   VaR_CornishFisher  ES_CF_EmpiricalTail Ticker     ReturnType Horizon  \n",
       "0           0.020356             0.037666   AAPL  SimpleReturns      1D  \n",
       "1           0.087784             0.092456   AAPL  SimpleReturns      1D  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ConfidenceLevel</th>\n",
       "      <th>VaR_Historical</th>\n",
       "      <th>ES_Historical</th>\n",
       "      <th>VaR_Gaussian</th>\n",
       "      <th>ES_Gaussian</th>\n",
       "      <th>VaR_CornishFisher</th>\n",
       "      <th>ES_CF_EmpiricalTail</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>ReturnType</th>\n",
       "      <th>Horizon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.032191</td>\n",
       "      <td>0.045673</td>\n",
       "      <td>0.033205</td>\n",
       "      <td>0.041819</td>\n",
       "      <td>0.020356</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>SimpleReturns</td>\n",
       "      <td>1D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.049229</td>\n",
       "      <td>0.071721</td>\n",
       "      <td>0.047253</td>\n",
       "      <td>0.054238</td>\n",
       "      <td>0.087784</td>\n",
       "      <td>0.092456</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>SimpleReturns</td>\n",
       "      <td>1D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 146
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tail Risk Metrics",
   "id": "95a7089cfa1749bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T21:05:58.246187Z",
     "start_time": "2025-12-26T21:05:58.238251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "\n",
    "def _as_price_series(x) -> pd.Series:\n",
    "    if isinstance(x, pd.Series):\n",
    "        s = x\n",
    "    elif isinstance(x, pd.DataFrame):\n",
    "        s = x.iloc[:, 0]\n",
    "    else:\n",
    "        raise TypeError(\"Expected pandas Series or DataFrame\")\n",
    "\n",
    "    s = s.dropna().copy()\n",
    "    s.index = pd.to_datetime(s.index).tz_localize(None)\n",
    "    return s\n",
    "\n",
    "def _as_return_series(x) -> pd.Series:\n",
    "    if isinstance(x, pd.Series):\n",
    "        s = x\n",
    "    elif isinstance(x, pd.DataFrame):\n",
    "        s = x.iloc[:, 0]\n",
    "    else:\n",
    "        raise TypeError(\"Expected pandas Series or DataFrame\")\n",
    "    s = s.dropna().copy()\n",
    "    s.index = pd.to_datetime(s.index).tz_localize(None)\n",
    "    return s\n",
    "\n",
    "# ---------- 1) Worst N daily returns ----------\n",
    "\n",
    "def worst_n_returns(returns: pd.Series, n: int = 10) -> pd.DataFrame:\n",
    "    r = _as_return_series(returns)\n",
    "    worst = r.nsmallest(n)\n",
    "    return pd.DataFrame({\n",
    "        \"Date\": worst.index.date,\n",
    "        \"Return\": worst.values\n",
    "    }).reset_index(drop=True)\n",
    "\n",
    "# ---------- 2) Tail quantiles ----------\n",
    "\n",
    "def tail_quantiles(returns: pd.Series, qs=(0.01, 0.05)) -> dict:\n",
    "    r = _as_return_series(returns).to_numpy()\n",
    "    out = {}\n",
    "    for q in qs:\n",
    "        out[f\"Q{int(q*100):02d}\"] = float(np.quantile(r, q))  # return quantile (left tail)\n",
    "    return out\n",
    "\n",
    "# ---------- Drawdown series & episodes ----------\n",
    "\n",
    "def drawdown_series(prices) -> pd.DataFrame:\n",
    "    p = _as_price_series(prices)\n",
    "    running_max = p.cummax()\n",
    "    dd = p / running_max - 1.0\n",
    "    return pd.DataFrame({\"Price\": p, \"RunningMax\": running_max, \"Drawdown\": dd})\n",
    "\n",
    "def drawdown_episodes(prices) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retourne un DF par √©pisode de drawdown (peak->trough->recovery),\n",
    "    avec la profondeur max et la dur√©e (jours de trading).\n",
    "    \"\"\"\n",
    "    dd_df = drawdown_series(prices)\n",
    "    dd = dd_df[\"Drawdown\"]\n",
    "    p = dd_df[\"Price\"]\n",
    "\n",
    "    in_dd = dd < 0\n",
    "    episode_id = (in_dd != in_dd.shift(1, fill_value=False)).cumsum()\n",
    "\n",
    "    episodes = []\n",
    "    for eid, block in dd_df[in_dd].groupby(episode_id[in_dd]):\n",
    "        start_date = block.index[0]\n",
    "        trough_date = block[\"Drawdown\"].idxmin()\n",
    "        depth = float(block[\"Drawdown\"].min())  # n√©gatif\n",
    "        length = int(len(block))                # trading days in drawdown\n",
    "\n",
    "        # peak date = dernier max avant l'√©pisode\n",
    "        peak_date = p.loc[:start_date].idxmax()\n",
    "\n",
    "        # recovery = premi√®re date apr√®s la fin du block o√π Price >= Price@peak\n",
    "        peak_price = float(p.loc[peak_date].item())\n",
    "        after = p.loc[block.index[-1]:]\n",
    "        rec = after[after >= peak_price]\n",
    "        recovery_date = rec.index[0] if not rec.empty else None\n",
    "        recovered = recovery_date is not None\n",
    "\n",
    "        episodes.append({\n",
    "            \"EpisodeId\": int(eid),\n",
    "            \"PeakDate\": peak_date.date(),\n",
    "            \"StartDate\": start_date.date(),\n",
    "            \"TroughDate\": trough_date.date(),\n",
    "            \"RecoveryDate\": None if recovery_date is None else recovery_date.date(),\n",
    "            \"Recovered\": bool(recovered),\n",
    "            \"MaxDrawdown\": depth,     # n√©gatif\n",
    "            \"Length_trading_days\": length\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(episodes)\n",
    "\n",
    "# ---------- 3) Drawdown tail distribution ----------\n",
    "\n",
    "def drawdown_tail_distribution(prices, qs=(0.01, 0.05, 0.10)) -> dict:\n",
    "    ep = drawdown_episodes(prices)\n",
    "    if ep.empty:\n",
    "        return {\"NumEpisodes\": 0}\n",
    "\n",
    "    depths = ep[\"MaxDrawdown\"].to_numpy()  # n√©gatif\n",
    "    out = {\"NumEpisodes\": int(len(depths))}\n",
    "    for q in qs:\n",
    "        out[f\"DD_Q{int(q*100):02d}\"] = float(np.quantile(depths, q))  # plus n√©gatif => pire\n",
    "    out[\"DD_Min\"] = float(np.min(depths))\n",
    "    out[\"DD_Median\"] = float(np.median(depths))\n",
    "    return out\n",
    "\n",
    "# ---------- 4) Tail concentration risk ----------\n",
    "\n",
    "def tail_concentration_risk(returns: pd.Series, n: int = 10) -> dict:\n",
    "    \"\"\"\n",
    "    Mesure combien les pires jours expliquent la perte totale.\n",
    "    - SumLoss: somme des returns n√©gatifs en absolu (approx, sans compounding)\n",
    "    - TopN_LossShare: part des pires N jours dans la perte totale\n",
    "    - HHI_TopN: concentration des pires N jours (plus haut = plus concentr√©)\n",
    "    \"\"\"\n",
    "    r = _as_return_series(returns)\n",
    "\n",
    "    neg = r[r < 0]\n",
    "    if neg.empty:\n",
    "        return {\"SumLoss\": 0.0, \"TopN_LossShare\": 0.0, \"HHI_TopN\": 0.0, \"NumNegativeDays\": 0}\n",
    "\n",
    "    losses = (-neg).to_numpy()  # positive losses\n",
    "    sum_loss = float(losses.sum())\n",
    "\n",
    "    worst = (-r.nsmallest(n)).to_numpy()  # pires N jours, pertes positives\n",
    "    worst = worst[worst > 0]\n",
    "\n",
    "    topn_share = float(worst.sum() / sum_loss) if sum_loss > 0 and worst.size else 0.0\n",
    "\n",
    "    # HHI (Herfindahl-Hirschman Index) sur les pires N pertes\n",
    "    # HHI proche de 1 => un jour explique quasi tout le tail\n",
    "    if worst.size:\n",
    "        w = worst / worst.sum()\n",
    "        hhi = float(np.sum(w**2))\n",
    "    else:\n",
    "        hhi = 0.0\n",
    "\n",
    "    return {\n",
    "        \"NumNegativeDays\": int(len(neg)),\n",
    "        \"SumLoss\": sum_loss,\n",
    "        \"TopN_LossShare\": topn_share,\n",
    "        \"HHI_TopN\": hhi,\n",
    "        \"N\": int(n),\n",
    "    }\n",
    "\n",
    "# ---------- Orchestrator ----------\n",
    "\n",
    "def tail_risk_report_from_prices(prices: pd.Series, worst_n: int = 10) -> dict:\n",
    "    p = _as_price_series(prices)\n",
    "    rets = p.pct_change()\n",
    "\n",
    "    return {\n",
    "        \"TailQuantiles\": tail_quantiles(rets, qs=(0.01, 0.05)),\n",
    "        \"WorstNReturns\": worst_n_returns(rets, n=worst_n),\n",
    "        \"DrawdownTail\": drawdown_tail_distribution(p, qs=(0.01, 0.05, 0.10)),\n",
    "        \"TailConcentration\": tail_concentration_risk(rets, n=worst_n),\n",
    "        \"Observations\": int(rets.dropna().shape[0]),\n",
    "    }\n",
    "\n",
    "def yahoo_tail_risk_report(ticker: str, start_date: str, end_date: str, worst_n: int = 10) -> dict:\n",
    "    df = yf.download(\n",
    "        ticker,\n",
    "        start=start_date,\n",
    "        end=pd.to_datetime(end_date) + pd.Timedelta(days=1),\n",
    "        auto_adjust=True,\n",
    "        progress=False\n",
    "    )\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No data for {ticker}\")\n",
    "\n",
    "    prices = _as_price_series(df[\"Close\"])\n",
    "    out = tail_risk_report_from_prices(prices, worst_n=worst_n)\n",
    "    out[\"Ticker\"] = ticker\n",
    "    out[\"PriceType\"] = \"Adjusted Close\"\n",
    "    out[\"ReturnType\"] = \"SimpleReturns\"\n",
    "    out[\"Horizon\"] = \"1D\"\n",
    "    return out\n"
   ],
   "id": "286e572e1e645278",
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T21:21:31.518772Z",
     "start_time": "2025-12-26T21:21:31.469697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "report = yahoo_tail_risk_report(\"AAPL\", \"2018-01-01\", \"2024-01-01\", worst_n=10)\n",
    "\n",
    "report[\"TailQuantiles\"]          # 1% / 5% quantiles\n",
    "report[\"WorstNReturns\"]          # tableau des pires jours\n",
    "report[\"DrawdownTail\"]           # quantiles des drawdowns par √©pisode\n",
    "report[\"TailConcentration\"]      # concentration des pertes\n"
   ],
   "id": "94ed56d0db6d0562",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NumNegativeDays': 701,\n",
       " 'SumLoss': 9.701534544721548,\n",
       " 'TopN_LossShare': 0.08321573907662265,\n",
       " 'HHI_TopN': 0.10673227190536694,\n",
       " 'N': 10}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T22:48:43.658949Z",
     "start_time": "2025-12-26T22:48:43.653154Z"
    }
   },
   "cell_type": "code",
   "source": "report[\"TailQuantiles\"]",
   "id": "c769f78594547c86",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q01': -0.05231255924898922, 'Q05': -0.030711761178462582}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T22:49:04.303931Z",
     "start_time": "2025-12-26T22:49:04.301009Z"
    }
   },
   "cell_type": "code",
   "source": "report[\"WorstNReturns\"]",
   "id": "f21efd6c0859e210",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Date    Return\n",
       "0  2020-03-16 -0.128647\n",
       "1  2019-01-03 -0.099607\n",
       "2  2020-03-12 -0.098755\n",
       "3  2020-09-03 -0.080061\n",
       "4  2020-03-09 -0.079092\n",
       "5  2020-09-08 -0.067295\n",
       "6  2018-11-02 -0.066331\n",
       "7  2020-02-27 -0.065368\n",
       "8  2020-03-20 -0.063485\n",
       "9  2022-09-13 -0.058679"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>-0.128647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>-0.099607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>-0.098755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-09-03</td>\n",
       "      <td>-0.080061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>-0.079092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-09-08</td>\n",
       "      <td>-0.067295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-11-02</td>\n",
       "      <td>-0.066331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>-0.065368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>-0.063485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-09-13</td>\n",
       "      <td>-0.058679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T22:49:19.068525Z",
     "start_time": "2025-12-26T22:49:19.066507Z"
    }
   },
   "cell_type": "code",
   "source": "report[\"DrawdownTail\"]",
   "id": "4d804446893b84f8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NumEpisodes': 65,\n",
       " 'DD_Q01': -0.33979171601705876,\n",
       " 'DD_Q05': -0.2002024890930363,\n",
       " 'DD_Q10': -0.125500314359433,\n",
       " 'DD_Min': -0.3851591466877471,\n",
       " 'DD_Median': -0.016196975332883334}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T22:49:56.630859Z",
     "start_time": "2025-12-26T22:49:56.628774Z"
    }
   },
   "cell_type": "code",
   "source": "report[\"TailConcentration\"]",
   "id": "da784b74054c7c24",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NumNegativeDays': 701,\n",
       " 'SumLoss': 9.701534544721548,\n",
       " 'TopN_LossShare': 0.08321573907662265,\n",
       " 'HHI_TopN': 0.10673227190536694,\n",
       " 'N': 10}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 150
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9dccdddb255f72e4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
